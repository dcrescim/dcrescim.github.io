<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Linear Regression Code pt 2</title>
  <meta name="author" content="Dan">



  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="/favicon.png" rel="icon">
  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
  </script>

  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>


  <link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="/">Test</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/" rel="subscribe-rss">RSS</a></li>
</ul>

<!-- TODO: add search here
<form action="" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
-->

<ul class="main-navigation">
    <!-- TODO: add categories here? -->
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Linear Regression Code pt 2</h1>
      <p class="meta"><time datetime="2014-03-06T00:00:00" pubdate>Thu 06 March 2014</time></p>
</header>

  <div class="entry-content"><div class="section" id="last-time">
<h2>Last Time</h2>
<p>This post is a continuation of the previous post which writes our first pass at Linear Regression. Here is a <a class="reference external" href="/linear-regression-code-pt-1.html">link</a> .</p>
<p>We ended with this last time.</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">dot</span><span class="p">,</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">multiply</span>

<span class="k">class</span> <span class="nc">SquaredError</span><span class="p">:</span>
  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">T</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="c"># Force into real number</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">T</span>
    <span class="n">squares</span> <span class="o">=</span> <span class="n">multiply</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">squares</span><span class="p">)</span><span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">m</span><span class="p">)</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">T</span><span class="p">):</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span><span class="c"># Force into real number</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">Y</span><span class="o">-</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">diff</span><span class="o">/</span><span class="n">rows</span>

<span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">:</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">error_func</span><span class="o">=</span><span class="n">SquaredError</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">error_func</span> <span class="o">=</span> <span class="n">error_func</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="k">if</span> <span class="n">W</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">init_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">rows</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
      <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">a</span><span class="p">,</span>
      <span class="n">high</span> <span class="o">=</span> <span class="n">a</span><span class="p">,</span>
      <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">)</span>
    <span class="p">))</span>

  <span class="k">def</span> <span class="nf">error</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_func</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">T</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">Y_e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_func</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">T</span><span class="p">)</span>
    <span class="n">W_e</span> <span class="o">=</span> <span class="n">dot</span><span class="p">(</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">Y_e</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">*</span><span class="n">W_e</span>


  <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">T</span><span class="p">):</span>
    <span class="c"># If we haven&#39;t created an internal matrix</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">init_matrix</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">):</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">print</span> <span class="s">&quot;Error: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">T</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">T</span><span class="p">)</span>
</pre></div>
<p>We need to add the intercept term to our model. We could go the route of just appending a column of 1's onto our matrix X, and then running the model like normal. But this approach doesn't really scale to Neural Net's. Here is an image of a 3 layer (2 matrix) Neural Net.</p>
<img alt="2 Matrix Neural Net" src="theme/images/3-LayerNeuralNetv2.png" />
<p>Yes, we didn't cover Neural Net's yet, but we can still imagine the consequences of our decisions. Consider a generalization of our linear model where we have more internal matrices (which is exactly what a Neural Net is).</p>
<p>If we have something like this, then every time we dot two matrices, we need to take the resultant matrix, and add a column of 1's. This means that we need to malloc space for a new bigger matrix, and then fill it with the correct values. This is slow, and can be done better.</p>
<p>So we opt for different idea. Namely, we are going to add an intercept term to the model, making sure to update it correctly on the reverse trip (the update step).</p>
</div>
<div class="section" id="initialization">
<h2>Initialization</h2>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">error_func</span><span class="o">=</span><span class="n">SquaredError</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">error_func</span> <span class="o">=</span> <span class="n">error_func</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>

  <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="k">if</span> <span class="n">W</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
<p>We need some boilerplate functions to initialize the matrices correctly.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">init_intercept</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">):</span>
  <span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">rows</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
    <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">a</span><span class="p">,</span>
    <span class="n">high</span> <span class="o">=</span> <span class="n">a</span><span class="p">,</span>
    <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">cols</span><span class="p">)</span>
  <span class="p">))</span>

<span class="k">def</span> <span class="nf">init_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">):</span>
  <span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">rows</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
    <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">a</span><span class="p">,</span>
    <span class="n">high</span> <span class="o">=</span> <span class="n">a</span><span class="p">,</span>
    <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">)</span>
  <span class="p">))</span>
</pre></div>
<p>I need to update both the forward pass. Which is the <strong>predict</strong> method.</p>
</div>
<div class="section" id="predict">
<h2>Predict</h2>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
</pre></div>
<p>But wait?! How does this work. The dot product of dot(X, self.W) returns a matrix, and the other element is an numpy array. Welcome to the big bad world of numpy broadcasting. The main idea of broadcasting is that numpy will try to understand the context of the calculation and <strong>broadcast</strong> your array into a matrix, so that these things can be added together. Check it <a class="reference external" href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">out</a> .</p>
<p>Moving along, we write our update</p>
</div>
<div class="section" id="update">
<h2>Update</h2>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>

  <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
  <span class="n">dJ_dY</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_func</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">T</span><span class="p">)</span>
  <span class="n">dJ_dW</span> <span class="o">=</span> <span class="n">dot</span><span class="p">(</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">dJ_dY</span><span class="p">)</span>
  <span class="n">dJ_db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dJ_dY</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">*</span><span class="n">dJ_dW</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">*</span><span class="n">dJ_db</span>
</pre></div>
<p>Where did that last line come from. Well I like to imagine adding an invisible column of 1's to X, and placing the intercept at the bottom of $W$. This looks like this</p>
<p>[image with column of 1's, and bottom of $W$ is an intercept]</p>
<p>Then you imagine the calculation of $X^{T} \cdot \dfrac{dJ}{dY}$ (which you showed to be the correct partials), and imagine what value you add to the intercept.</p>
<p>That last column is</p>
<p>[image of row of ones and dotted with dJ/dY]</p>
<p>We see that it is just the vertical sum of whatever is in dJ/dY. Pretty nifty eh?</p>
</div>
<div class="section" id="testing">
<h2>Testing</h2>
<p>We test our implementation by splitting the boston housing data into training and testing sets, and then testing it against what the scikit learn linear regression returns.</p>
<p>The code looks like this.</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">dot</span><span class="p">,</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">multiply</span>

<span class="k">class</span> <span class="nc">SquaredError</span><span class="p">:</span>
  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">T</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="c"># Force into real number</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">T</span>
    <span class="n">squares</span> <span class="o">=</span> <span class="n">multiply</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">squares</span><span class="p">)</span><span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">m</span><span class="p">)</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">T</span><span class="p">):</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="c"># Force into real number</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">Y</span><span class="o">-</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">diff</span><span class="o">/</span><span class="n">rows</span>

<span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">:</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">error_func</span><span class="o">=</span><span class="n">SquaredError</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">error_func</span> <span class="o">=</span> <span class="n">error_func</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="k">if</span> <span class="n">W</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">init_intercept</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">rows</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
      <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">a</span><span class="p">,</span>
      <span class="n">high</span> <span class="o">=</span> <span class="n">a</span><span class="p">,</span>
      <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">cols</span><span class="p">)</span>
    <span class="p">))</span>

  <span class="k">def</span> <span class="nf">init_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">rows</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
      <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">a</span><span class="p">,</span>
      <span class="n">high</span> <span class="o">=</span> <span class="n">a</span><span class="p">,</span>
      <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">)</span>
    <span class="p">))</span>

  <span class="k">def</span> <span class="nf">error</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_func</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">T</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>

  <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">dJ_dY</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_func</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">T</span><span class="p">)</span>
    <span class="n">dJ_dW</span> <span class="o">=</span> <span class="n">dot</span><span class="p">(</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">dJ_dY</span><span class="p">)</span>
    <span class="n">dJ_db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dJ_dY</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">*</span><span class="n">dJ_dW</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">*</span><span class="n">dJ_db</span>


  <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">T</span><span class="p">):</span>
    <span class="c"># If we haven&#39;t created an internal matrix</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">init_matrix</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">init_intercept</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">):</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">print</span> <span class="s">&quot;Error: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">T</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">T</span><span class="p">)</span>

<span class="c"># Get the Boston Regression Data</span>
<span class="n">boston</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_boston</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="c"># Split into training and testing chunks</span>
<span class="n">offset</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">T_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">offset</span><span class="p">],</span> <span class="n">T</span><span class="p">[:</span><span class="n">offset</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">T_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">offset</span><span class="p">:],</span> <span class="n">T</span><span class="p">[</span><span class="n">offset</span><span class="p">:]</span>

<span class="c"># Preprocess the X data, by using a scaling each feature</span>
<span class="c"># independently. Scale both the test/train sets</span>
<span class="n">X_scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_normed</span> <span class="o">=</span> <span class="n">X_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_normed</span> <span class="o">=</span> <span class="n">X_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c"># Create our linear model</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">L</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_normed</span><span class="p">,</span> <span class="n">T_train</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;Our Test Set Error: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">L</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">X_test_normed</span><span class="p">,</span> <span class="n">T_test</span><span class="p">)</span>

<span class="c"># Use sklearn&#39;s linear model to see how we did</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_normed</span><span class="p">,</span> <span class="n">T_train</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;Scikit-Learn Test Set Error: </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">SquaredError</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_normed</span><span class="p">),</span> <span class="n">T_test</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="output">
<h2>Output</h2>
<div class="highlight"><pre><span class="n">Error</span><span class="p">:</span> <span class="mf">293.691754</span>
<span class="n">Error</span><span class="p">:</span> <span class="mf">10.417053</span>
<span class="n">Error</span><span class="p">:</span> <span class="mf">10.324612</span>
<span class="n">Error</span><span class="p">:</span> <span class="mf">10.304189</span>
<span class="n">Error</span><span class="p">:</span> <span class="mf">10.298527</span>
<span class="n">Error</span><span class="p">:</span> <span class="mf">10.296912</span>
<span class="n">Error</span><span class="p">:</span> <span class="mf">10.296450</span>
<span class="n">Error</span><span class="p">:</span> <span class="mf">10.296318</span>
<span class="n">Error</span><span class="p">:</span> <span class="mf">10.296280</span>
<span class="n">Error</span><span class="p">:</span> <span class="mf">10.296269</span>
<span class="n">Our</span> <span class="n">Test</span> <span class="n">Set</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">18.249858</span>
<span class="n">Scikit</span><span class="o">-</span><span class="n">Learn</span> <span class="n">Test</span> <span class="n">Set</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">18.248582</span>
</pre></div>
<p>Till next time.</p>
</div>
</div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">Dan Crescimanno</span>
  </span>
<time datetime="2014-03-06T00:00:00" pubdate>Thu 06 March 2014</time></p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/logistic-classification-code.html">Logistic Classification Code</a>
      </li>
      <li class="post">
          <a href="/building-outward-toward-classification.html">Building outward toward Classification</a>
      </li>
      <li class="post">
          <a href="/linear-regression-code-pt-2.html">Linear Regression Code pt 2</a>
      </li>
      <li class="post">
          <a href="/linear-regression-code-pt-1.html">Linear Regression Code pt 1</a>
      </li>
      <li class="post">
          <a href="/linear-regression.html">Linear Regression</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/python-math.html">python, math</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="/" type="application/rss+xml" rel="alternate">RSS</a></li>
            <li><a href="#" target="_blank">You can add links in your config file</a></li>
            <li><a href="#" target="_blank">Another social link</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://getpelican.com/" target="_blank">Pelican</a></li>
            <li><a href="http://python.org/" target="_blank">Python.org</a></li>
            <li><a href="http://jinja.pocoo.org/" target="_blank">Jinja2</a></li>
            <li><a href="#" target="_blank">You can modify those links in your config file</a></li>
        </ul>
    </section>

</aside><aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/logistic-classification-code.html">Logistic Classification Code</a>
      </li>
      <li class="post">
          <a href="/building-outward-toward-classification.html">Building outward toward Classification</a>
      </li>
      <li class="post">
          <a href="/linear-regression-code-pt-2.html">Linear Regression Code pt 2</a>
      </li>
      <li class="post">
          <a href="/linear-regression-code-pt-1.html">Linear Regression Code pt 1</a>
      </li>
      <li class="post">
          <a href="/linear-regression.html">Linear Regression</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/python-math.html">python, math</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="/" type="application/rss+xml" rel="alternate">RSS</a></li>
            <li><a href="#" target="_blank">You can add links in your config file</a></li>
            <li><a href="#" target="_blank">Another social link</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://getpelican.com/" target="_blank">Pelican</a></li>
            <li><a href="http://python.org/" target="_blank">Python.org</a></li>
            <li><a href="http://jinja.pocoo.org/" target="_blank">Jinja2</a></li>
            <li><a href="#" target="_blank">You can modify those links in your config file</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Dan -
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
</body>
</html>